<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Object Detection</title>
  <!-- TensorFlow.jsとCOCO-SSDモデルを読み込む -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <style>
    body {
      margin: 0;
      padding: 0;
      width: 100vw;
      height: 100vh;
      display: flex;
      flex-direction: column;
      align-items: center;
      background: #000;
    }
    .container {
      width: 100%;
      height: 85vh;
      position: relative;
      overflow: hidden;
    }
    #output {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    .button-container {
      position: fixed;
      bottom: 20px;
      width: 100%;
      display: flex;
      justify-content: center;
      gap: 20px;
      z-index: 1000;
    }
    button {
      padding: 15px 30px;
      font-size: 18px;
      border-radius: 25px;
      border: none;
      background: rgba(255, 255, 255, 0.9);
      box-shadow: 0 2px 5px rgba(0,0,0,0.2);
    }
    .message {
      position: fixed;
      bottom: 100px;
      left: 50%;
      transform: translateX(-50%);
      background-color: rgba(0, 0, 0, 0.7);
      color: white;
      padding: 10px 20px;
      border-radius: 5px;
      font-size: 20px;
      z-index: 1000;
    }
  </style>
</head>
<body>
  <div class="container">
    <canvas id="output"></canvas>
    <video id="input" style="display: none;" playsinline></video>
  </div>
  <div class="button-container">
    <button id="start">start</button>
    <button id="stop">stop</button>
  </div>
  <div class="message" id="message"></div>

  <script>
    const video = document.getElementById('input');
    const canvas = document.getElementById('output');
    const messageDiv = document.getElementById('message');
    const ctx = canvas.getContext('2d');
    let model = null;
    let isRunning = false;

    // キャンバスのサイズをウィンドウに合わせる
    function resizeCanvas() {
      const container = document.querySelector('.container');
      canvas.width = container.clientWidth;
      canvas.height = container.clientHeight;
    }
    
    resizeCanvas();
    window.addEventListener('resize', resizeCanvas);

    // モデルの読み込み
    async function loadModel() {
      messageDiv.textContent = 'モデルを読み込んでいます...';
      try {
        model = await cocoSsd.load();
        messageDiv.textContent = 'モデルの読み込みが完了しました';
      } catch (error) {
        console.error('モデル読み込みエラー:', error);
        messageDiv.textContent = 'モデルの読み込みに失敗しました';
      }
    }

    // カメラのセットアップ
    async function setupCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: { exact: "environment" },
            width: { ideal: 1280 },
            height: { ideal: 720 }
          },
          audio: false
        });
        video.srcObject = stream;
        return new Promise((resolve) => {
          video.onloadedmetadata = () => {
            video.play();
            resolve();
          };
        });
      } catch (error) {
        console.error('カメラエラー:', error);
        messageDiv.textContent = 'カメラを起動できませんでした';
        throw error;
      }
    }

    // 物体検出の実行
    async function detectObjects() {
      if (!isRunning) return;
      
      try {
        const predictions = await model.detect(video);
        
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        
        predictions.forEach(prediction => {
          // 境界ボックスを描画
          ctx.strokeStyle = '#00FF00';
          ctx.lineWidth = 4;
          ctx.strokeRect(
            prediction.bbox[0] * (canvas.width / video.videoWidth),
            prediction.bbox[1] * (canvas.height / video.videoHeight),
            prediction.bbox[2] * (canvas.width / video.videoWidth),
            prediction.bbox[3] * (canvas.height / video.videoHeight)
          );
          
          // ラベルを表示
          const score = (prediction.score * 100).toFixed(1);
          messageDiv.textContent = `${prediction.class} (${score}%)`;
        });
      } catch (error) {
        console.error('検出エラー:', error);
      }
      
      requestAnimationFrame(detectObjects);
    }

    // 開始ボタンの処理
    document.getElementById('start').addEventListener('click', async () => {
      try {
        if (!model) {
          await loadModel();
        }
        await setupCamera();
        isRunning = true;
        detectObjects();
      } catch (error) {
        console.error('起動エラー:', error);
      }
    });

    // 停止ボタンの処理
    document.getElementById('stop').addEventListener('click', () => {
      isRunning = false;
      if (video.srcObject) {
        video.srcObject.getTracks().forEach(track => track.stop());
      }
      video.srcObject = null;
      messageDiv.textContent = '';
      ctx.clearRect(0, 0, canvas.width, canvas.height);
    });

    // 初期化時にモデルを読み込む
    loadModel();
  </script>
</body>
</html>